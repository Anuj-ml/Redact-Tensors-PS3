{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9f2526e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T12:13:45.936295Z",
     "iopub.status.busy": "2025-11-22T12:13:45.936086Z",
     "iopub.status.idle": "2025-11-22T12:14:02.092617Z",
     "shell.execute_reply": "2025-11-22T12:14:02.091812Z"
    },
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports completed!\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports and Setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv, GATConv, global_mean_pool\n",
    "from torch_geometric.utils import to_networkx\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, accuracy_score\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "print(\"Imports completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b20ebcaa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T12:14:02.095966Z",
     "iopub.status.busy": "2025-11-22T12:14:02.095490Z",
     "iopub.status.idle": "2025-11-22T12:14:02.178251Z",
     "shell.execute_reply": "2025-11-22T12:14:02.177501Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Dataset shape: (9841, 51)\n",
      "After dropna shape: (7121, 51)\n",
      "Feature shape: (7121, 48)\n",
      "Fraud cases: 1350 (18.96%)\n",
      "\n",
      "Train set: 4984 samples\n",
      "Test set: 2137 samples\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Data Loading and Preprocessing\n",
    "print(\"Loading dataset...\")\n",
    "df = pd.read_csv('transaction_dataset.csv')\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "\n",
    "# Basic cleaning\n",
    "df = df.dropna().reset_index(drop=True)\n",
    "print(f\"After dropna shape: {df.shape}\")\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(columns=['Address', 'FLAG', 'Index'] if 'Index' in df.columns else ['Address', 'FLAG'])\n",
    "y = df['FLAG'].values\n",
    "\n",
    "# Handle non-numeric columns\n",
    "for col in X.columns:\n",
    "    X[col] = pd.to_numeric(X[col], errors='coerce')\n",
    "\n",
    "# Fill remaining NaN values\n",
    "X = X.fillna(0)\n",
    "\n",
    "# Scale features\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = pd.DataFrame(\n",
    "    scaler.fit_transform(X),\n",
    "    columns=X.columns,\n",
    "    index=X.index\n",
    ")\n",
    "\n",
    "print(f\"Feature shape: {X_scaled.shape}\")\n",
    "print(f\"Fraud cases: {y.sum()} ({y.sum()/len(y)*100:.2f}%)\")\n",
    "\n",
    "# Convert to numpy\n",
    "X_np = X_scaled.values.astype(np.float32)\n",
    "y_np = y.astype(np.int64)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_np, y_np, test_size=0.3, random_state=42, stratify=y_np\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain set: {X_train.shape[0]} samples\")\n",
    "print(f\"Test set: {X_test.shape[0]} samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec49d8ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T12:14:02.180774Z",
     "iopub.status.busy": "2025-11-22T12:14:02.180555Z",
     "iopub.status.idle": "2025-11-22T12:14:02.184990Z",
     "shell.execute_reply": "2025-11-22T12:14:02.184286Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph construction function defined!\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Graph Construction Function\n",
    "def build_knn_graph(features, k=10):\n",
    "    \"\"\"\n",
    "    Build a graph using K-nearest neighbors based on feature similarity\n",
    "    \"\"\"\n",
    "    from sklearn.neighbors import NearestNeighbors\n",
    "    \n",
    "    nbrs = NearestNeighbors(n_neighbors=k+1, metric='cosine').fit(features)\n",
    "    distances, indices = nbrs.kneighbors(features)\n",
    "    \n",
    "    # Create edge list (excluding self-loops)\n",
    "    edge_list = []\n",
    "    edge_weights = []\n",
    "    \n",
    "    for i in range(len(features)):\n",
    "        for j, idx in enumerate(indices[i][1:]):  # Skip first (self)\n",
    "            edge_list.append([i, idx])\n",
    "            # Convert distance to similarity weight\n",
    "            weight = 1 - distances[i][j+1]\n",
    "            edge_weights.append(max(0, weight))\n",
    "    \n",
    "    edge_index = torch.tensor(edge_list, dtype=torch.long).t().contiguous()\n",
    "    edge_attr = torch.tensor(edge_weights, dtype=torch.float32)\n",
    "    \n",
    "    return edge_index, edge_attr\n",
    "\n",
    "print(\"Graph construction function defined!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df80002f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T12:14:02.187242Z",
     "iopub.status.busy": "2025-11-22T12:14:02.187033Z",
     "iopub.status.idle": "2025-11-22T12:14:03.016005Z",
     "shell.execute_reply": "2025-11-22T12:14:03.015217Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building graph structure...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of edges: 74760\n",
      "\n",
      "Graph Data:\n",
      "  Nodes: 4984\n",
      "  Edges: 74760\n",
      "  Node features: 48\n",
      "  Classes: tensor([0, 1])\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Build Training Graph\n",
    "print(\"\\nBuilding graph structure...\")\n",
    "edge_index, edge_weights = build_knn_graph(X_train, k=15)\n",
    "print(f\"Number of edges: {edge_index.shape[1]}\")\n",
    "\n",
    "# Create PyTorch Geometric Data object\n",
    "x = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index, edge_attr=edge_weights, y=y_tensor)\n",
    "\n",
    "print(f\"\\nGraph Data:\")\n",
    "print(f\"  Nodes: {data.num_nodes}\")\n",
    "print(f\"  Edges: {data.num_edges}\")\n",
    "print(f\"  Node features: {data.num_node_features}\")\n",
    "print(f\"  Classes: {data.y.unique()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2619a694",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T12:14:03.018543Z",
     "iopub.status.busy": "2025-11-22T12:14:03.018338Z",
     "iopub.status.idle": "2025-11-22T12:14:03.024634Z",
     "shell.execute_reply": "2025-11-22T12:14:03.024029Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNN Model class defined!\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Define GNN Model\n",
    "class FraudGNN(nn.Module):\n",
    "    def __init__(self, num_features, hidden_dim=64, num_classes=2, dropout=0.3):\n",
    "        super(FraudGNN, self).__init__()\n",
    "        \n",
    "        # Graph Convolutional Layers\n",
    "        self.conv1 = GCNConv(num_features, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.conv3 = GCNConv(hidden_dim, hidden_dim // 2)\n",
    "        \n",
    "        # Batch normalization\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.bn3 = nn.BatchNorm1d(hidden_dim // 2)\n",
    "        \n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # Classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_dim // 2, hidden_dim // 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim // 4, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, edge_index, edge_attr=None):\n",
    "        # Graph convolutions\n",
    "        x = self.conv1(x, edge_index, edge_attr)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.conv2(x, edge_index, edge_attr)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.conv3(x, edge_index, edge_attr)\n",
    "        x = self.bn3(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # Node-level predictions\n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "print(\"GNN Model class defined!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f9f0061",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T12:14:03.027134Z",
     "iopub.status.busy": "2025-11-22T12:14:03.026824Z",
     "iopub.status.idle": "2025-11-22T12:14:03.122949Z",
     "shell.execute_reply": "2025-11-22T12:14:03.122368Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Model parameters: 33,826\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Initialize Model and Setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = FraudGNN(\n",
    "    num_features=data.num_node_features,\n",
    "    hidden_dim=128,\n",
    "    num_classes=2,\n",
    "    dropout=0.3\n",
    ").to(device)\n",
    "\n",
    "data = data.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=5e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bf99b31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T12:14:03.125192Z",
     "iopub.status.busy": "2025-11-22T12:14:03.124988Z",
     "iopub.status.idle": "2025-11-22T12:14:03.130096Z",
     "shell.execute_reply": "2025-11-22T12:14:03.129470Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluation functions defined!\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Training and Evaluation Functions\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index, data.edge_attr)\n",
    "    loss = criterion(out, data.y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "def evaluate(features, labels, edge_index, edge_attr):\n",
    "    \"\"\"Fixed evaluation function that accepts edge_index and edge_attr\"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(features, edge_index, edge_attr)\n",
    "        pred = out.argmax(dim=1)\n",
    "        acc = (pred == labels).float().mean().item()\n",
    "        loss = criterion(out, labels).item()\n",
    "    return acc, loss, pred.cpu().numpy(), F.softmax(out, dim=1)[:, 1].cpu().numpy()\n",
    "\n",
    "print(\"Training and evaluation functions defined!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "295a6c3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T12:14:03.132457Z",
     "iopub.status.busy": "2025-11-22T12:14:03.132050Z",
     "iopub.status.idle": "2025-11-22T12:14:06.732079Z",
     "shell.execute_reply": "2025-11-22T12:14:06.730288Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training GNN model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 020, Loss: 0.2661, Acc: 0.8104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping at epoch 25\n",
      "\n",
      "Best training accuracy: 0.8790\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Training Loop\n",
    "print(\"\\nTraining GNN model...\")\n",
    "num_epochs = 200\n",
    "best_acc = 0\n",
    "patience = 20\n",
    "patience_counter = 0\n",
    "\n",
    "train_losses = []\n",
    "train_accs = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    loss = train()\n",
    "    acc, val_loss, _, _ = evaluate(data.x, data.y, data.edge_index, data.edge_attr)\n",
    "    \n",
    "    train_losses.append(loss)\n",
    "    train_accs.append(acc)\n",
    "    \n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        patience_counter = 0\n",
    "        # Save best model\n",
    "        torch.save(model.state_dict(), 'best_gnn_model.pt')\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "    \n",
    "    if (epoch + 1) % 20 == 0:\n",
    "        print(f'Epoch {epoch+1:03d}, Loss: {loss:.4f}, Acc: {acc:.4f}')\n",
    "    \n",
    "    if patience_counter >= patience:\n",
    "        print(f\"Early stopping at epoch {epoch+1}\")\n",
    "        break\n",
    "\n",
    "# Load best model\n",
    "model.load_state_dict(torch.load('best_gnn_model.pt'))\n",
    "print(f\"\\nBest training accuracy: {best_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec1fe561",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T12:14:06.736094Z",
     "iopub.status.busy": "2025-11-22T12:14:06.735784Z",
     "iopub.status.idle": "2025-11-22T12:14:06.797299Z",
     "shell.execute_reply": "2025-11-22T12:14:06.796516Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Results:\n",
      "  Accuracy: 0.8790\n",
      "  Loss: 0.6847\n"
     ]
    }
   ],
   "source": [
    "# Cell 9: Evaluate on Training Set\n",
    "train_acc, train_loss, train_pred, train_proba = evaluate(data.x, data.y, data.edge_index, data.edge_attr)\n",
    "print(f\"\\nTraining Results:\")\n",
    "print(f\"  Accuracy: {train_acc:.4f}\")\n",
    "print(f\"  Loss: {train_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1835104",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T12:14:06.800255Z",
     "iopub.status.busy": "2025-11-22T12:14:06.800038Z",
     "iopub.status.idle": "2025-11-22T12:14:06.929876Z",
     "shell.execute_reply": "2025-11-22T12:14:06.929132Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Building test graph...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Results:\n",
      "  Accuracy: 0.8685\n",
      "  Loss: 0.6846\n"
     ]
    }
   ],
   "source": [
    "# Cell 10: Build Test Graph and Evaluate\n",
    "print(\"\\nBuilding test graph...\")\n",
    "edge_index_test, edge_weights_test = build_knn_graph(X_test, k=15)\n",
    "x_test = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long).to(device)\n",
    "data_test = Data(x=x_test, edge_index=edge_index_test.to(device), \n",
    "                 edge_attr=edge_weights_test.to(device), y=y_test_tensor).to(device)\n",
    "\n",
    "# Evaluate on test set\n",
    "test_acc, test_loss, test_pred, test_proba = evaluate(data_test.x, data_test.y, \n",
    "                                                       data_test.edge_index, data_test.edge_attr)\n",
    "print(f\"\\nTest Results:\")\n",
    "print(f\"  Accuracy: {test_acc:.4f}\")\n",
    "print(f\"  Loss: {test_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1dd31a3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T12:14:06.932118Z",
     "iopub.status.busy": "2025-11-22T12:14:06.931881Z",
     "iopub.status.idle": "2025-11-22T12:14:06.942788Z",
     "shell.execute_reply": "2025-11-22T12:14:06.942064Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report (Test Set):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Legitimate       0.92      0.91      0.92      1732\n",
      "       Fraud       0.65      0.68      0.66       405\n",
      "\n",
      "    accuracy                           0.87      2137\n",
      "   macro avg       0.78      0.79      0.79      2137\n",
      "weighted avg       0.87      0.87      0.87      2137\n",
      "\n",
      "\n",
      "Confusion Matrix (Test Set):\n",
      "[[1582  150]\n",
      " [ 131  274]]\n",
      "\n",
      "ROC AUC Score: 0.9244\n"
     ]
    }
   ],
   "source": [
    "# Cell 11: Classification Metrics\n",
    "print(\"\\nClassification Report (Test Set):\")\n",
    "print(classification_report(y_test, test_pred, target_names=['Legitimate', 'Fraud']))\n",
    "\n",
    "print(\"\\nConfusion Matrix (Test Set):\")\n",
    "print(confusion_matrix(y_test, test_pred))\n",
    "\n",
    "# ROC AUC Score\n",
    "try:\n",
    "    roc_auc = roc_auc_score(y_test, test_proba)\n",
    "    print(f\"\\nROC AUC Score: {roc_auc:.4f}\")\n",
    "except:\n",
    "    print(\"\\nROC AUC Score: Could not calculate (possibly only one class present)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4049b3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T12:14:06.945101Z",
     "iopub.status.busy": "2025-11-22T12:14:06.944882Z",
     "iopub.status.idle": "2025-11-22T12:14:06.954392Z",
     "shell.execute_reply": "2025-11-22T12:14:06.953715Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving model and preprocessing objects...\n",
      "Model saved as 'gnn_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "# Cell 12: Save Model Pipeline\n",
    "print(\"\\nSaving model and preprocessing objects...\")\n",
    "\n",
    "# Create a dictionary with all necessary components\n",
    "gnn_pipeline = {\n",
    "    'model': model,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'scaler': scaler,\n",
    "    'num_features': data.num_node_features,\n",
    "    'hidden_dim': 128,\n",
    "    'num_classes': 2,\n",
    "    'k_neighbors': 15,\n",
    "    'feature_names': X.columns.tolist()\n",
    "}\n",
    "\n",
    "# Save as pickle\n",
    "with open('gnn_model.pkl', 'wb') as f:\n",
    "    pickle.dump(gnn_pipeline, f)\n",
    "\n",
    "print(\"Model saved as 'gnn_model.pkl'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b25e538",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T12:14:06.956560Z",
     "iopub.status.busy": "2025-11-22T12:14:06.956332Z",
     "iopub.status.idle": "2025-11-22T12:14:06.961667Z",
     "shell.execute_reply": "2025-11-22T12:14:06.960900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction function defined!\n"
     ]
    }
   ],
   "source": [
    "# Cell 13: Prediction Function\n",
    "def predict_fraud(address_features, model_pipeline, k_neighbors=15):\n",
    "    \"\"\"\n",
    "    Predict fraud for new address features\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    address_features : array-like, shape (n_samples, n_features)\n",
    "        Feature matrix for addresses to predict\n",
    "    model_pipeline : dict\n",
    "        Loaded GNN pipeline dictionary\n",
    "    k_neighbors : int\n",
    "        Number of neighbors for graph construction\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    predictions : array, shape (n_samples,)\n",
    "        Binary predictions (0: Legitimate, 1: Fraud)\n",
    "    probabilities : array, shape (n_samples,)\n",
    "        Fraud probabilities\n",
    "    \"\"\"\n",
    "    model = model_pipeline['model']\n",
    "    scaler = model_pipeline['scaler']\n",
    "    \n",
    "    # Preprocess\n",
    "    features_df = pd.DataFrame(address_features, columns=model_pipeline['feature_names'])\n",
    "    for col in features_df.columns:\n",
    "        features_df[col] = pd.to_numeric(features_df[col], errors='coerce')\n",
    "    features_df = features_df.fillna(0)\n",
    "    \n",
    "    features_scaled = scaler.transform(features_df)\n",
    "    features_tensor = torch.tensor(features_scaled, dtype=torch.float32).to(device)\n",
    "    \n",
    "    # Build graph\n",
    "    edge_index, edge_weights = build_knn_graph(features_scaled, k=k_neighbors)\n",
    "    edge_index = edge_index.to(device)\n",
    "    edge_weights = edge_weights.to(device)\n",
    "    \n",
    "    # Predict\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(features_tensor, edge_index, edge_weights)\n",
    "        probs = F.softmax(out, dim=1)\n",
    "        preds = out.argmax(dim=1).cpu().numpy()\n",
    "        fraud_probs = probs[:, 1].cpu().numpy()\n",
    "    \n",
    "    return preds, fraud_probs\n",
    "\n",
    "print(\"Prediction function defined!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dcbdb7cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-22T12:14:06.963959Z",
     "iopub.status.busy": "2025-11-22T12:14:06.963626Z",
     "iopub.status.idle": "2025-11-22T12:14:06.967604Z",
     "shell.execute_reply": "2025-11-22T12:14:06.966917Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "GNN Model Training Complete!\n",
      "==================================================\n",
      "\n",
      "Model file: gnn_model.pkl\n",
      "Model architecture: 3-layer GCN with hidden_dim=128\n",
      "Training accuracy: 0.8790\n",
      "Test accuracy: 0.8685\n"
     ]
    }
   ],
   "source": [
    "# Cell 14: Final Summary\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"GNN Model Training Complete!\")\n",
    "print(\"=\"*50)\n",
    "print(f\"\\nModel file: gnn_model.pkl\")\n",
    "print(f\"Model architecture: 3-layer GCN with hidden_dim=128\")\n",
    "print(f\"Training accuracy: {train_acc:.4f}\")\n",
    "print(f\"Test accuracy: {test_acc:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
